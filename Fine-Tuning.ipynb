{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import time\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Vérifier la disponibilité du GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define SENet Module\n",
    "class SENet(nn.Module):\n",
    "    def _init_(self, channels, reduction=16):\n",
    "        super(SENet, self)._init_()\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.global_avg_pool(x).view(b, c)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.sigmoid(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "# Define CBAM Module\n",
    "class CBAMBlock(nn.Module):\n",
    "    def _init_(self, channels, reduction=16, kernel_size=7):\n",
    "        super(CBAMBlock, self)._init_()\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // reduction, channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.channel_attention(x)\n",
    "        x = x * y\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        y = torch.cat([avg_out, max_out], dim=1)\n",
    "        y = self.spatial_attention(y)\n",
    "        x = x * y\n",
    "        return x\n",
    "\n",
    "# Define Hybrid Module (SENet + CBAM)\n",
    "class Hybrid(nn.Module):\n",
    "    def _init_(self, channels):\n",
    "        super(Hybrid, self)._init_()\n",
    "        self.senet = SENet(channels)\n",
    "        self.cbam = CBAMBlock(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.senet(x)\n",
    "        x = self.cbam(x)\n",
    "        return x\n",
    "\n",
    "# Apply Attention Modules to SqueezeNet\n",
    "def modify_model_with_attention(model, attention_module, layer_name):\n",
    "    for name, module in model.named_modules():\n",
    "        if name == layer_name:\n",
    "            out_channels = module.out_channels if isinstance(module, nn.Conv2d) else None\n",
    "            if out_channels:\n",
    "                if attention_module == 'SENet':\n",
    "                    attention = SENet(out_channels)\n",
    "                elif attention_module == 'CBAM':\n",
    "                    attention = CBAMBlock(out_channels)\n",
    "                elif attention_module == 'Hybrid':\n",
    "                    attention = Hybrid(out_channels)\n",
    "                else:\n",
    "                    continue\n",
    "                setattr(model, name, nn.Sequential(module, attention))\n",
    "    return model\n",
    "\n",
    "# Data Preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, test_loader, epochs, criterion, optimizer):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    train_loss, val_loss, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss, correct_train = 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss, correct_val = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_val_loss += loss.item()\n",
    "                correct_val += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        train_loss.append(total_train_loss / len(train_loader))\n",
    "        val_loss.append(total_val_loss / len(test_loader))\n",
    "        train_acc.append(correct_train / len(train_loader.dataset))\n",
    "        val_acc.append(correct_val / len(test_loader.dataset))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {train_loss[-1]:.4f}, Val Loss: {val_loss[-1]:.4f}, Train Acc: {train_acc[-1]:.4f}, Val Acc: {val_acc[-1]:.4f}\")\n",
    "\n",
    "    return train_loss, val_loss, train_acc, val_acc\n",
    "\n",
    "# Model Definitions\n",
    "squeezenet_base = models.squeezenet1_0(pretrained=True)\n",
    "squeezenet_senet = modify_model_with_attention(models.squeezenet1_0(pretrained=True), 'SENet', 'features.12')\n",
    "squeezenet_cbam = modify_model_with_attention(models.squeezenet1_0(pretrained=True), 'CBAM', 'features.12')\n",
    "squeezenet_hybrid = modify_model_with_attention(models.squeezenet1_0(pretrained=True), 'Hybrid', 'features.12')\n",
    "\n",
    "models_to_train = {\n",
    "    \"SqueezeNet Base\": squeezenet_base,\n",
    "    \"SqueezeNet + SENet\": squeezenet_senet,\n",
    "    \"SqueezeNet + CBAM\": squeezenet_cbam,\n",
    "    \"SqueezeNet + Hybrid\": squeezenet_hybrid\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "results = {}\n",
    "\n",
    "for name, model in models_to_train.items():\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(f\"Training {name}\")\n",
    "    results[name] = train_model(model, train_loader, test_loader, epochs, criterion, optimizer)\n",
    "\n",
    "# Plotting Results\n",
    "plt.figure(figsize=(8, 4))\n",
    "for name, (train_loss, val_loss, train_acc, val_acc) in results.items():\n",
    "    plt.plot(train_loss, label=f'{name} Train Loss')\n",
    "    plt.plot(val_loss, label=f'{name} Val Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "for name, (train_loss, val_loss, train_acc, val_acc) in results.items():\n",
    "    plt.plot(train_acc, label=f'{name} Train Accuracy')\n",
    "    plt.plot(val_acc, label=f'{name} Val Accuracy')\n",
    "plt.title('Accuracy Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Define your DataLoader objects for training and validation\n",
    "dataloaders = {\n",
    "    'train': train_loader,  # Replace with your actual train DataLoader\n",
    "    'val': test_loader  # Replace with your actual validation DataLoader\n",
    "}\n",
    "\n",
    "# Define the class names for CIFAR-10\n",
    "class_names = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "# Define the imshow function (if not already defined)\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)  # Ensure the data is in the range [0, 1] for display\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "# Visualize model predictions\n",
    "def visualize_model(model, num_images=10):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(2, num_images // 2, images_so_far)  # Arrange images in 2 rows\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "    model.train(mode=was_training)\n",
    "\n",
    "# Call the visualization function\n",
    "visualize_model(model)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction_summary(preds, class_names):\n",
    "    prediction_counts = {class_name: 0 for class_name in class_names}\n",
    "    for pred in preds:\n",
    "        prediction_counts[class_names[pred]] += 1\n",
    "    print(\"Prediction Summary:\")\n",
    "    for class_name, count in prediction_counts.items():\n",
    "        print(f\"{class_name}: {count}\")\n",
    "\n",
    "# Visualize model predictions with additional debug information\n",
    "def visualize_model_grid_debug(model, num_classes=10, samples_per_class=5):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(num_classes, samples_per_class, figsize=(15, 15))\n",
    "\n",
    "    counters = [0] * num_classes\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                class_idx = preds[j].item()\n",
    "\n",
    "                if counters[class_idx] < samples_per_class:\n",
    "                    ax = axes[class_idx, counters[class_idx]]\n",
    "                    ax.axis('off')\n",
    "\n",
    "                    img = inputs.cpu().data[j].numpy().transpose(1, 2, 0)\n",
    "                    img = (img - img.min()) / (img.max() - img.min())  # Normalize\n",
    "                    ax.imshow(img)\n",
    "                    ax.set_title(f'Predicted: {class_names[class_idx]}')\n",
    "\n",
    "                    counters[class_idx] += 1\n",
    "\n",
    "                if sum(counters) >= num_classes * samples_per_class:\n",
    "                    model.train(mode=was_training)\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    print_prediction_summary(all_preds, class_names)\n",
    "                    return\n",
    "\n",
    "    model.train(mode=was_training)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print_prediction_summary(all_preds, class_names)\n",
    "\n",
    "# Call the visualization function with debugging\n",
    "visualize_model_grid_debug(model)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define SENet Module\n",
    "class SENet(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SENet, self).__init__()\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.global_avg_pool(x).view(b, c)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.sigmoid(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "# Define CBAM Module\n",
    "class CBAMBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super(CBAMBlock, self).__init__()\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // reduction, channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.channel_attention(x)\n",
    "        x = x * y\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        y = torch.cat([avg_out, max_out], dim=1)\n",
    "        y = self.spatial_attention(y)\n",
    "        x = x * y\n",
    "        return x\n",
    "\n",
    "# Define Hybrid Module (SENet + CBAM)\n",
    "class Hybrid(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.senet = SENet(channels)\n",
    "        self.cbam = CBAMBlock(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.senet(x)\n",
    "        x = self.cbam(x)\n",
    "        return x\n",
    "\n",
    "# Apply Attention Modules to ResNet18\n",
    "def modify_model_with_attention(model, attention_module, layer_name):\n",
    "    for name, module in model.named_modules():\n",
    "        if name == layer_name:\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                out_channels = module.out_channels\n",
    "            else:\n",
    "                continue  # Ignorer les couches non Conv2d\n",
    "\n",
    "            if attention_module == 'SENet':\n",
    "                attention = SENet(out_channels)\n",
    "            elif attention_module == 'CBAM':\n",
    "                attention = CBAMBlock(out_channels)\n",
    "            elif attention_module == 'Hybrid':\n",
    "                attention = Hybrid(out_channels)\n",
    "            else:\n",
    "                raise ValueError(\"Module d'attention non reconnu\")\n",
    "\n",
    "            # Remplacer la couche par une séquence (couche originale + module d'attention)\n",
    "            parent_name = '.'.join(layer_name.split('.')[:-1])\n",
    "            child_name = layer_name.split('.')[-1]\n",
    "            parent_module = model\n",
    "            for part in parent_name.split('.'):\n",
    "                parent_module = getattr(parent_module, part)\n",
    "            setattr(parent_module, child_name, nn.Sequential(module, attention))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Data Preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, test_loader, epochs, criterion, optimizer):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    train_loss, val_loss, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss, correct_train = 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss, correct_val = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_val_loss += loss.item()\n",
    "                correct_val += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        train_loss.append(total_train_loss / len(train_loader))\n",
    "        val_loss.append(total_val_loss / len(test_loader))\n",
    "        train_acc.append(correct_train / len(train_loader.dataset))\n",
    "        val_acc.append(correct_val / len(test_loader.dataset))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {train_loss[-1]:.4f}, Val Loss: {val_loss[-1]:.4f}, Train Acc: {train_acc[-1]:.4f}, Val Acc: {val_acc[-1]:.4f}\")\n",
    "\n",
    "    return train_loss, val_loss, train_acc, val_acc\n",
    "\n",
    "# Model Definitions\n",
    "resnet_base = models.resnet18(pretrained=True)\n",
    "resnet_senet = modify_model_with_attention(models.resnet18(pretrained=True), 'SENet', 'layer4.1.conv2')\n",
    "resnet_cbam = modify_model_with_attention(models.resnet18(pretrained=True), 'CBAM', 'layer4.1.conv2')\n",
    "resnet_hybrid = modify_model_with_attention(models.resnet18(pretrained=True), 'Hybrid', 'layer4.1.conv2')\n",
    "\n",
    "models_to_train = {\n",
    "    \"ResNet Base\": resnet_base,\n",
    "    \"ResNet + SENet\": resnet_senet,\n",
    "    \"ResNet + CBAM\": resnet_cbam,\n",
    "    \"ResNet + Hybrid\": resnet_hybrid\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "results = {}\n",
    "\n",
    "for name, model in models_to_train.items():\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(f\"Training {name}\")\n",
    "    results[name] = train_model(model, train_loader, test_loader, epochs, criterion, optimizer)\n",
    "\n",
    "# Plotting Results\n",
    "plt.figure(figsize=(8, 4))\n",
    "for name, (train_loss, val_loss, train_acc, val_acc) in results.items():\n",
    "    plt.plot(train_loss, label=f'{name} Train Loss')\n",
    "    plt.plot(val_loss, label=f'{name} Val Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "for name, (train_loss, val_loss, train_acc, val_acc) in results.items():\n",
    "    plt.plot(train_acc, label=f'{name} Train Accuracy')\n",
    "    plt.plot(val_acc, label=f'{name} Val Accuracy')\n",
    "plt.title('Accuracy Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define SENet Module\n",
    "class SENet(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SENet, self).__init__()\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.global_avg_pool(x).view(b, c)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.sigmoid(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "# Define CBAM Module\n",
    "class CBAMBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16, kernel_size=7):\n",
    "        super(CBAMBlock, self).__init__()\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels // reduction, channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.channel_attention(x)\n",
    "        x = x * y\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        y = torch.cat([avg_out, max_out], dim=1)\n",
    "        y = self.spatial_attention(y)\n",
    "        x = x * y\n",
    "        return x\n",
    "\n",
    "# Define Hybrid Module (SENet + CBAM)\n",
    "class Hybrid(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.senet = SENet(channels)\n",
    "        self.cbam = CBAMBlock(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.senet(x)\n",
    "        x = self.cbam(x)\n",
    "        return x\n",
    "\n",
    "# Apply Attention Modules to VGG\n",
    "def modify_model_with_attention(model, attention_module, layer_name):\n",
    "    for name, module in model.named_modules():\n",
    "        if name == layer_name:\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                out_channels = module.out_channels\n",
    "            else:\n",
    "                continue  # Ignorer les couches non Conv2d\n",
    "\n",
    "            if attention_module == 'SENet':\n",
    "                attention = SENet(out_channels)\n",
    "            elif attention_module == 'CBAM':\n",
    "                attention = CBAMBlock(out_channels)\n",
    "            elif attention_module == 'Hybrid':\n",
    "                attention = Hybrid(out_channels)\n",
    "            else:\n",
    "                raise ValueError(\"Module d'attention non reconnu\")\n",
    "\n",
    "            # Remplacer la couche par une séquence (couche originale + module d'attention)\n",
    "            parent_name = '.'.join(layer_name.split('.')[:-1])\n",
    "            child_name = layer_name.split('.')[-1]\n",
    "            parent_module = model\n",
    "            for part in parent_name.split('.'):\n",
    "                parent_module = getattr(parent_module, part)\n",
    "            setattr(parent_module, child_name, nn.Sequential(module, attention))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Data Preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Réduire la taille des images\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # Augmenter le batch_size\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Training Function\n",
    "def train_model(model, train_loader, test_loader, epochs, criterion, optimizer):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    train_loss, val_loss, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss, correct_train = 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "            correct_train += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss, correct_val = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_val_loss += loss.item()\n",
    "                correct_val += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "        train_loss.append(total_train_loss / len(train_loader))\n",
    "        val_loss.append(total_val_loss / len(test_loader))\n",
    "        train_acc.append(correct_train / len(train_loader.dataset))\n",
    "        val_acc.append(correct_val / len(test_loader.dataset))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Train Loss: {train_loss[-1]:.4f}, Val Loss: {val_loss[-1]:.4f}, Train Acc: {train_acc[-1]:.4f}, Val Acc: {val_acc[-1]:.4f}\")\n",
    "\n",
    "    return train_loss, val_loss, train_acc, val_acc\n",
    "\n",
    "# Model Definitions\n",
    "vgg_base = models.vgg16(pretrained=True)\n",
    "vgg_senet = modify_model_with_attention(models.vgg16(pretrained=True), 'SENet', 'features.28')\n",
    "vgg_cbam = modify_model_with_attention(models.vgg16(pretrained=True), 'CBAM', 'features.28')\n",
    "vgg_hybrid = modify_model_with_attention(models.vgg16(pretrained=True), 'Hybrid', 'features.28')\n",
    "\n",
    "models_to_train = {\n",
    "    \"VGG Base\": vgg_base,\n",
    "    \"VGG + SENet\": vgg_senet,\n",
    "    \"VGG + CBAM\": vgg_cbam,\n",
    "    \"VGG + Hybrid\": vgg_hybrid\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "results = {}\n",
    "\n",
    "for name, model in models_to_train.items():\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(f\"Training {name}\")\n",
    "    results[name] = train_model(model, train_loader, test_loader, epochs, criterion, optimizer)\n",
    "\n",
    "# Plotting Results\n",
    "plt.figure(figsize=(8, 4))\n",
    "for name, (train_loss, val_loss, train_acc, val_acc) in results.items():\n",
    "    plt.plot(train_loss, label=f'{name} Train Loss')\n",
    "    plt.plot(val_loss, label=f'{name} Val Loss')\n",
    "plt.title('Loss Curves')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "for name, (train_loss, val_loss, train_acc, val_acc) in results.items():\n",
    "    plt.plot(train_acc, label=f'{name} Train Accuracy')\n",
    "    plt.plot(val_acc, label=f'{name} Val Accuracy')\n",
    "plt.title('Accuracy Curves')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
