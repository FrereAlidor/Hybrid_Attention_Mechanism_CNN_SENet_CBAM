{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Import required packages from Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "\n",
    "# moves your model to train on your gpu if available else it uses your cpu\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning SqueezeNet...\n",
      "Epoch [1/3], Loss: 1.6566\n",
      "Epoch [2/3], Loss: 1.2102\n",
      "Epoch [3/3], Loss: 1.0144\n",
      "\n",
      "Fine-tuning VGG16...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFine-tuning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     79\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Function to evaluate model performance\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_model\u001b[39m(model, testloader):\n",
      "Cell \u001b[1;32mIn[2], line 70\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, trainloader, criterion, optimizer, epochs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     68\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 70\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(trainloader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Check the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Prepare transformations for CIFAR-10 with data augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
    "\n",
    "class_names = trainset.classes\n",
    "\n",
    "# Initialize models on the correct device\n",
    "squeezenet = models.squeezenet1_0(weights=models.SqueezeNet1_0_Weights.DEFAULT).to(device)\n",
    "vgg = models.vgg16(weights=models.VGG16_Weights.DEFAULT).to(device)\n",
    "resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(device)\n",
    "alexnet = models.alexnet(weights=models.AlexNet_Weights.DEFAULT).to(device)\n",
    "\n",
    "# Modify models for CIFAR-10\n",
    "squeezenet.classifier[1] = nn.Conv2d(512, 10, kernel_size=1).to(device)\n",
    "vgg.classifier[6] = nn.Linear(4096, 10).to(device)\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 10).to(device)\n",
    "alexnet.classifier[6] = nn.Linear(4096, 10).to(device)\n",
    "\n",
    "models_dict = {\n",
    "    \"SqueezeNet\": squeezenet,\n",
    "    \"VGG16\": vgg,\n",
    "    \"ResNet18\": resnet,\n",
    "    \"AlexNet\": alexnet\n",
    "}\n",
    "\n",
    "# Training function\n",
    "def train_model(model, trainloader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(trainloader):.4f}\")\n",
    "\n",
    "# Train models\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 3\n",
    "\n",
    "for name, model in models_dict.items():\n",
    "    print(f\"\\nFine-tuning {name}...\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_model(model, trainloader, criterion, optimizer, epochs)\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, testloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(f\"Confusion Matrix - {model.__class__.__name__}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate each model\n",
    "for name, model in models_dict.items():\n",
    "    print(f\"\\nEvaluating {name}...\")\n",
    "    evaluate_model(model, testloader)\n",
    "\n",
    "# Function to generate Grad-CAM\n",
    "def generate_gradcam(model, img_tensor, target_layer):\n",
    "    def hook_fn(module, input, output):\n",
    "        model_output.append(output)\n",
    "\n",
    "    model_output = []\n",
    "    handle = target_layer.register_forward_hook(hook_fn)\n",
    "    output = model(img_tensor.to(device))\n",
    "    handle.remove()\n",
    "\n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "    pred_score = F.softmax(output, dim=1)[0][pred_class].item()\n",
    "\n",
    "    grad_output = torch.autograd.grad(output[:, pred_class], model_output[0])[0]\n",
    "    weights = grad_output.mean(dim=(2, 3), keepdim=True)\n",
    "\n",
    "    gradcam = torch.sum(weights * model_output[0], dim=1).squeeze()\n",
    "    gradcam = F.relu(gradcam)\n",
    "\n",
    "    if gradcam.max() > 0:\n",
    "        gradcam = gradcam / gradcam.max()\n",
    "\n",
    "    return gradcam.cpu(), pred_class, pred_score\n",
    "\n",
    "# Visualizing Grad-CAM\n",
    "def visualize_gradcam_on_image(img_tensor, model, target_layer):\n",
    "    gradcam, pred_class, pred_score = generate_gradcam(model, img_tensor, target_layer)\n",
    "\n",
    "    gradcam_resized = cv2.resize(gradcam.detach().numpy(), (224, 224))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * gradcam_resized), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "\n",
    "    img = img_tensor.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "    img = np.clip(img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406], 0, 1)\n",
    "\n",
    "    cam_img = heatmap + np.float32(img)\n",
    "    cam_img = cam_img / np.max(cam_img)\n",
    "\n",
    "    return cam_img, pred_class, pred_score\n",
    "\n",
    "# Display Grad-CAM with predictions\n",
    "def display_gradcam_for_models(images, models_dict, class_names):\n",
    "    fig, axes = plt.subplots(len(images), len(models_dict) * 3, figsize=(len(models_dict) * 6, len(images) * 3))\n",
    "\n",
    "    for img_idx, img_tensor in enumerate(images):\n",
    "        img = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "        img = np.clip(img * [0.229, 0.224, 0.225] + [0.485, 0.456, 0.406], 0, 1)\n",
    "\n",
    "        for model_idx, (model_name, model) in enumerate(models_dict.items()):\n",
    "            if \"SqueezeNet\" in model_name:\n",
    "                target_layer = model.features[12]\n",
    "            elif \"VGG16\" in model_name:\n",
    "                target_layer = model.features[-1]\n",
    "            elif \"ResNet18\" in model_name:\n",
    "                target_layer = model.layer4[-1]\n",
    "            elif \"AlexNet\" in model_name:\n",
    "                target_layer = model.features[-1]\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model {model_name}.\")\n",
    "\n",
    "            cam_img, pred_class, pred_score = visualize_gradcam_on_image(img_tensor.unsqueeze(0).to(device), model, target_layer)\n",
    "\n",
    "            col_idx = model_idx * 3\n",
    "            axes[img_idx, col_idx].imshow(img)\n",
    "            axes[img_idx, col_idx].axis('off')\n",
    "            axes[img_idx, col_idx].set_title(f\"{model_name}\\nTrue: {class_names[labels[img_idx]]}\", fontsize=10)\n",
    "\n",
    "            axes[img_idx, col_idx + 1].imshow(cam_img)\n",
    "            axes[img_idx, col_idx + 1].axis('off')\n",
    "            axes[img_idx, col_idx + 1].set_title(f\"Predicted: {class_names[pred_class]} (P={pred_score:.2f})\", fontsize=10)\n",
    "\n",
    "            axes[img_idx, col_idx + 2].imshow(img, alpha=0.5)\n",
    "            axes[img_idx, col_idx + 2].imshow(cam_img, alpha=0.7)\n",
    "            axes[img_idx, col_idx + 2].axis('off')\n",
    "            axes[img_idx, col_idx + 2].set_title(\"Overlay\", fontsize=10)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.4)\n",
    "    plt.show()\n",
    "\n",
    "# Test on a batch\n",
    "images, labels = next(iter(testloader))\n",
    "display_gradcam_for_models(images[:5], models_dict, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
